{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Modelisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import seaborn as sns\r\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "from gensim.models import Phrases\r\n",
    "from gensim.corpora import Dictionary\r\n",
    "from gensim.models import LdaModel, CoherenceModel\r\n",
    "from gensim.models.LdaMulticore import LdaMulticore\r\n",
    "import pyLDAvis.gensim\r\n",
    "import pickle \r\n",
    "import pyLDAvis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Data preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv(\"datasets/posts_clean.csv\")\r\n",
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415192</td>\n",
       "      <td>good way create simple python web service</td>\n",
       "      <td>I use python year I little experience python w...</td>\n",
       "      <td>&lt;python&gt;&lt;web-services&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415344</td>\n",
       "      <td>log implementation prefer</td>\n",
       "      <td>I implement log class c try decide I curious k...</td>\n",
       "      <td>&lt;debugging&gt;&lt;language-agnostic&gt;&lt;logging&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414981</td>\n",
       "      <td>directly modify list element</td>\n",
       "      <td>I struct struct map public int size public map...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                      Title  \\\n",
       "0  415192  good way create simple python web service   \n",
       "1  415344                  log implementation prefer   \n",
       "2  414981               directly modify list element   \n",
       "\n",
       "                                                Body  \\\n",
       "0  I use python year I little experience python w...   \n",
       "1  I implement log class c try decide I curious k...   \n",
       "2  I struct struct map public int size public map...   \n",
       "\n",
       "                                      Tags  \n",
       "0                   <python><web-services>  \n",
       "1  <debugging><language-agnostic><logging>  \n",
       "2                               <c#><.net>  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# remove < and > around Tags\r\n",
    "data[\"Tags\"] = data[\"Tags\"].replace({\"<\" : \" \"}, regex=True)\r\n",
    "data[\"Tags\"] = data[\"Tags\"].replace({\">\" : \" \"}, regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415192</td>\n",
       "      <td>good way create simple python web service</td>\n",
       "      <td>I use python year I little experience python w...</td>\n",
       "      <td>python  web-services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415344</td>\n",
       "      <td>log implementation prefer</td>\n",
       "      <td>I implement log class c try decide I curious k...</td>\n",
       "      <td>debugging  language-agnostic  logging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414981</td>\n",
       "      <td>directly modify list element</td>\n",
       "      <td>I struct struct map public int size public map...</td>\n",
       "      <td>c#  .net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415580</td>\n",
       "      <td>regex name group java</td>\n",
       "      <td>understanding java regex package not support n...</td>\n",
       "      <td>java  regex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415753</td>\n",
       "      <td>instance cache objective c</td>\n",
       "      <td>I want cache instance certain class class keep...</td>\n",
       "      <td>objective-c  weak-references</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                      Title  \\\n",
       "0  415192  good way create simple python web service   \n",
       "1  415344                  log implementation prefer   \n",
       "2  414981               directly modify list element   \n",
       "3  415580                      regex name group java   \n",
       "4  415753                 instance cache objective c   \n",
       "\n",
       "                                                Body  \\\n",
       "0  I use python year I little experience python w...   \n",
       "1  I implement log class c try decide I curious k...   \n",
       "2  I struct struct map public int size public map...   \n",
       "3  understanding java regex package not support n...   \n",
       "4  I want cache instance certain class class keep...   \n",
       "\n",
       "                                      Tags  \n",
       "0                    python  web-services   \n",
       "1   debugging  language-agnostic  logging   \n",
       "2                                c#  .net   \n",
       "3                             java  regex   \n",
       "4            objective-c  weak-references   "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "docs = data[\"Body\"].to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Split the documents into tokens.\r\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\r\n",
    "for idx in range(len(docs)):\r\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\r\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\r\n",
    "\r\n",
    "# Remove numbers, but not words that contain numbers.\r\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\r\n",
    "\r\n",
    "# Remove words that are only one character.\r\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "lemmatizer = WordNetLemmatizer()\r\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Compute bigrams.\r\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\r\n",
    "bigram = Phrases(docs, min_count=20)\r\n",
    "for idx in range(len(docs)):\r\n",
    "    for token in bigram[docs[idx]]:\r\n",
    "        if '_' in token:\r\n",
    "            # Token is a bigram, add to document.\r\n",
    "            docs[idx].append(token)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Remove rare and common tokens.\r\n",
    "# Create a dictionary representation of the documents.\r\n",
    "dct = Dictionary(docs)\r\n",
    "dct.filter_extremes(no_below=20, no_above=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Bag-of-words representation of the documents.\r\n",
    "corpus = [dct.doc2bow(doc) for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print('Number of unique tokens: %d' % len(dct))\r\n",
    "print('Number of documents: %d' % len(corpus))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unique tokens: 24935\n",
      "Number of documents: 164598\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Topic Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Set training parameters.\r\n",
    "num_topics = 10\r\n",
    "chunksize = 2000\r\n",
    "passes = 20\r\n",
    "iterations = 400\r\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\r\n",
    "\r\n",
    "# Make a index to word dictionary.\r\n",
    "temp = dct[0]  # This is only to \"load\" the dictionary.\r\n",
    "id2word = dct.id2token\r\n",
    "\r\n",
    "model = LdaModel(\r\n",
    "    corpus=corpus,\r\n",
    "    id2word = id2word,\r\n",
    "    chunksize=chunksize,\r\n",
    "    alpha='auto',\r\n",
    "    eta='auto',\r\n",
    "    iterations=iterations,\r\n",
    "    num_topics=num_topics,\r\n",
    "    passes=passes,\r\n",
    "    eval_every=eval_every\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "coherence_model_lda = CoherenceModel(model=model, texts=docs, dictionary=dct, coherence='c_v')\r\n",
    "coherence_lda = coherence_model_lda.get_coherence()\r\n",
    "print('Coherence Score: ', coherence_lda)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Coherence Score:  0.5933901185688508\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def compute_coherence_values(corpus, dictionary, k, a, b):\r\n",
    "    lda_model = LdaMulticore(corpus=corpus,\r\n",
    "                        id2word = id2word,\r\n",
    "                        chunksize=chunksize,\r\n",
    "                        alpha=a,\r\n",
    "                        eta=b,\r\n",
    "                        iterations=iterations,\r\n",
    "                        num_topics=k,\r\n",
    "                        passes=passes,\r\n",
    "                        eval_every=eval_every)\r\n",
    "    \r\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=docs, dictionary=dct, coherence='c_v')\r\n",
    "    \r\n",
    "    return coherence_model_lda.get_coherence()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from gensim.utils import ClippedCorpus\r\n",
    "import gensim\r\n",
    "import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "grid = {}\r\n",
    "grid['Validation_Set'] = {}\r\n",
    "# Topics range\r\n",
    "min_topics = 2\r\n",
    "max_topics = 11\r\n",
    "step_size = 1\r\n",
    "topics_range = range(min_topics, max_topics, step_size)\r\n",
    "# Alpha parameter\r\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\r\n",
    "alpha.append('symmetric')\r\n",
    "alpha.append('asymmetric')\r\n",
    "# Beta parameter\r\n",
    "beta = list(np.arange(0.01, 1, 0.3))\r\n",
    "beta.append('symmetric')\r\n",
    "# Validation sets\r\n",
    "num_of_docs = len(corpus)\r\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \r\n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \r\n",
    "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \r\n",
    "               corpus]\r\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\r\n",
    "model_results = {'Validation_Set': [],\r\n",
    "                 'Topics': [],\r\n",
    "                 'Alpha': [],\r\n",
    "                 'Beta': [],\r\n",
    "                 'Coherence': []\r\n",
    "                }\r\n",
    "# Can take a long time to run\r\n",
    "if 1 == 1:\r\n",
    "    pbar = tqdm.tqdm(total=540)\r\n",
    "    \r\n",
    "    # iterate through validation corpuses\r\n",
    "    for i in range(len(corpus_sets)):\r\n",
    "        # iterate through number of topics\r\n",
    "        for k in topics_range:\r\n",
    "            # iterate through alpha values\r\n",
    "            for a in alpha:\r\n",
    "                # iterare through beta values\r\n",
    "                for b in beta:\r\n",
    "                    # get the coherence score for the given parameters\r\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dct, \r\n",
    "                                                  k=k, a=a, b=b)\r\n",
    "                    # Save the model results\r\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\r\n",
    "                    model_results['Topics'].append(k)\r\n",
    "                    model_results['Alpha'].append(a)\r\n",
    "                    model_results['Beta'].append(b)\r\n",
    "                    model_results['Coherence'].append(cv)\r\n",
    "                    \r\n",
    "                    pbar.update(1)\r\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\r\n",
    "    pbar.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/540 [01:13<?, ?it/s]\n",
      "  1%|          | 6/540 [19:28<29:25:07, 198.33s/it]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lda_model = LdaMulticore(corpus=corpus,\r\n",
    "                        id2word=id2word,\r\n",
    "                        num_topics=, \r\n",
    "                        random_state=100,\r\n",
    "                        chunksize=100,\r\n",
    "                        passes=10,\r\n",
    "                        alpha=,\r\n",
    "                        eta=)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize the topics\r\n",
    "pyLDAvis.enable_notebook()\r\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\r\n",
    "LDAvis_prepared"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "db691860837755bfd223dbb19bf59c90fd58faf4b85973e04a456a30cef6b76b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}