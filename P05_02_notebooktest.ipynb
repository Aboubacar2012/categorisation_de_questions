{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Modelisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import seaborn as sns\r\n",
    "from gensim.utils import ClippedCorpus\r\n",
    "import gensim\r\n",
    "import tqdm\r\n",
    "from gensim.models import Phrases\r\n",
    "from gensim.corpora import Dictionary\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "from gensim.models import LdaModel, CoherenceModel, LdaMulticore, TfidfModel, Nmf\r\n",
    "from nlp_module import remove_stopwords\r\n",
    "import pyLDAvis\r\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Data preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv(\"datasets/posts_clean.csv\")\r\n",
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415192</td>\n",
       "      <td>good way create simple python web service</td>\n",
       "      <td>I use python year I little experience python w...</td>\n",
       "      <td>&lt;python&gt;&lt;web-services&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415344</td>\n",
       "      <td>log implementation prefer</td>\n",
       "      <td>I implement log class c try decide I curious k...</td>\n",
       "      <td>&lt;debugging&gt;&lt;language-agnostic&gt;&lt;logging&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414981</td>\n",
       "      <td>directly modify list element</td>\n",
       "      <td>I struct struct map public int size public map...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                      Title  \\\n",
       "0  415192  good way create simple python web service   \n",
       "1  415344                  log implementation prefer   \n",
       "2  414981               directly modify list element   \n",
       "\n",
       "                                                Body  \\\n",
       "0  I use python year I little experience python w...   \n",
       "1  I implement log class c try decide I curious k...   \n",
       "2  I struct struct map public int size public map...   \n",
       "\n",
       "                                      Tags  \n",
       "0                   <python><web-services>  \n",
       "1  <debugging><language-agnostic><logging>  \n",
       "2                               <c#><.net>  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# remove < and > around Tags\r\n",
    "data[\"Tags\"] = data[\"Tags\"].replace({\"<\" : \" \"}, regex=True)\r\n",
    "data[\"Tags\"] = data[\"Tags\"].replace({\">\" : \" \"}, regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data[\"Body\"] = data[\"Body\"].str.lower()\r\n",
    "data[\"Body\"] = data[\"Body\"].apply(remove_stopwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415192</td>\n",
       "      <td>good way create simple python web service</td>\n",
       "      <td>use python year little experience python web p...</td>\n",
       "      <td>python  web-services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415344</td>\n",
       "      <td>log implementation prefer</td>\n",
       "      <td>implement log class c try decide curious know ...</td>\n",
       "      <td>debugging  language-agnostic  logging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414981</td>\n",
       "      <td>directly modify list element</td>\n",
       "      <td>struct struct map public int size public map i...</td>\n",
       "      <td>c#  .net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                      Title  \\\n",
       "0  415192  good way create simple python web service   \n",
       "1  415344                  log implementation prefer   \n",
       "2  414981               directly modify list element   \n",
       "\n",
       "                                                Body  \\\n",
       "0  use python year little experience python web p...   \n",
       "1  implement log class c try decide curious know ...   \n",
       "2  struct struct map public int size public map i...   \n",
       "\n",
       "                                      Tags  \n",
       "0                    python  web-services   \n",
       "1   debugging  language-agnostic  logging   \n",
       "2                                c#  .net   "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "docs = data[\"Body\"].to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Split the documents into tokens.\r\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\r\n",
    "for idx in range(len(docs)):\r\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\r\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\r\n",
    "\r\n",
    "# Remove numbers, but not words that contain numbers.\r\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\r\n",
    "\r\n",
    "# Remove words that are only one character.\r\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Compute bigrams.\r\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\r\n",
    "bigram = Phrases(docs, min_count=20)\r\n",
    "for idx in range(len(docs)):\r\n",
    "    for token in bigram[docs[idx]]:\r\n",
    "        if '_' in token:\r\n",
    "            # Token is a bigram, add to document.\r\n",
    "            docs[idx].append(token)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Remove rare and common tokens.\r\n",
    "# Create a dictionary representation of the documents.\r\n",
    "dct = Dictionary(docs)\r\n",
    "dct.filter_extremes(no_below=20, no_above=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Bag-of-words representation of the documents.\r\n",
    "corpus = [dct.doc2bow(doc) for doc in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model = TfidfModel(corpus)\r\n",
    "corpus = model[corpus]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('Number of unique tokens: %d' % len(dct))\r\n",
    "print('Number of documents: %d' % len(corpus))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of unique tokens: 25556\n",
      "Number of documents: 164598\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Topic Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Set training parameters.\r\n",
    "chunksize = 2000\r\n",
    "passes = 10\r\n",
    "iterations = 200\r\n",
    "eval_every = None\r\n",
    "\r\n",
    "# Make a index to word dictionary.\r\n",
    "temp = dct[0]  # This is only to \"load\" the dictionary.\r\n",
    "id2word = dct.id2token"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Non Negative Matrix Factorization (NMF)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Create a list of the topic numbers we want to try\r\n",
    "topic_nums = list(np.arange(2, 10 + 1, 1))\r\n",
    "\r\n",
    "# Run the nmf model and calculate the coherence score\r\n",
    "# for each number of topics\r\n",
    "coherence_scores = []\r\n",
    "\r\n",
    "for num in topic_nums:\r\n",
    "    nmf = Nmf(\r\n",
    "        corpus=corpus,\r\n",
    "        num_topics=num,\r\n",
    "        id2word=id2word,\r\n",
    "        chunksize=chunksize,\r\n",
    "        passes=passes,\r\n",
    "        kappa=.1,\r\n",
    "        minimum_probability=0.01,\r\n",
    "        w_max_iter=300,\r\n",
    "        w_stop_condition=0.0001,\r\n",
    "        h_max_iter=100,\r\n",
    "        h_stop_condition=0.001,\r\n",
    "        eval_every=eval_every,\r\n",
    "        normalize=True,\r\n",
    "        random_state=42)\r\n",
    "    \r\n",
    "# Run the coherence model to get the score\r\n",
    "    cm = CoherenceModel(\r\n",
    "        model=nmf,\r\n",
    "        texts=docs,\r\n",
    "        dictionary=dct,\r\n",
    "        coherence='c_v')\r\n",
    "    \r\n",
    "    coherence_scores.append(round(cm.get_coherence(), 5))\r\n",
    "\r\n",
    "# Get the number of topics with the highest coherence score\r\n",
    "scores = list(zip(topic_nums, coherence_scores))\r\n",
    "best_num_topics = sorted(scores, key=lambda elem: elem[1], reverse=True)[0][0]\r\n",
    "\r\n",
    "print(\"Best number:\", best_num_topics)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topics number: 8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "nmf = Nmf(corpus,\r\n",
    "          id2word = id2word,\r\n",
    "          chunksize = 2000,\r\n",
    "          num_topics=8,\r\n",
    "          kappa=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "coherence_model_nmf = CoherenceModel(model=nmf, texts=docs, dictionary=dct, coherence='c_v')\r\n",
    "coherence_nmf = coherence_model_nmf.get_coherence()\r\n",
    "print('Coherence Score: ', coherence_nmf)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coherence Score:  0.5154724021115131\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Latent Dirichlet Allocation (LDA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def compute_coherence_values(corpus, dictionary, k, a, b):\r\n",
    "    lda_model = LdaMulticore(corpus=corpus,\r\n",
    "                        id2word = id2word,\r\n",
    "                        chunksize=chunksize,\r\n",
    "                        alpha=a,\r\n",
    "                        eta=b,\r\n",
    "                        iterations=iterations,\r\n",
    "                        num_topics=k,\r\n",
    "                        passes=passes,\r\n",
    "                        eval_every=eval_every)\r\n",
    "    \r\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=docs, dictionary=dct, coherence='c_v')\r\n",
    "    \r\n",
    "    return coherence_model_lda.get_coherence()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "grid = {}\r\n",
    "grid['Validation_Set'] = {}\r\n",
    "# Topics range\r\n",
    "min_topics = 2\r\n",
    "max_topics = 11\r\n",
    "step_size = 1\r\n",
    "topics_range = range(min_topics, max_topics, step_size)\r\n",
    "# Alpha parameter\r\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\r\n",
    "alpha.append('symmetric')\r\n",
    "alpha.append('asymmetric')\r\n",
    "# Beta parameter\r\n",
    "beta = list(np.arange(0.01, 1, 0.3))\r\n",
    "beta.append('symmetric')\r\n",
    "# Validation sets\r\n",
    "num_of_docs = len(corpus)\r\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \r\n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \r\n",
    "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \r\n",
    "               corpus]\r\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\r\n",
    "model_results = {'Validation_Set': [],\r\n",
    "                 'Topics': [],\r\n",
    "                 'Alpha': [],\r\n",
    "                 'Beta': [],\r\n",
    "                 'Coherence': []\r\n",
    "                }\r\n",
    "# Can take a long time to run\r\n",
    "if 1 == 1:\r\n",
    "    pbar = tqdm.tqdm(total=540)\r\n",
    "    \r\n",
    "    # iterate through validation corpuses\r\n",
    "    for i in range(len(corpus_sets)):\r\n",
    "        # iterate through number of topics\r\n",
    "        for k in topics_range:\r\n",
    "            # iterate through alpha values\r\n",
    "            for a in alpha:\r\n",
    "                # iterare through beta values\r\n",
    "                for b in beta:\r\n",
    "                    # get the coherence score for the given parameters\r\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=dct, \r\n",
    "                                                  k=k, a=a, b=b)\r\n",
    "                    # Save the model results\r\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\r\n",
    "                    model_results['Topics'].append(k)\r\n",
    "                    model_results['Alpha'].append(a)\r\n",
    "                    model_results['Beta'].append(b)\r\n",
    "                    model_results['Coherence'].append(cv)\r\n",
    "                    \r\n",
    "                    pbar.update(1)\r\n",
    "    pd.DataFrame(model_results).to_csv('datasets/lda_tuning_results.csv', index=False)\r\n",
    "    pbar.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 52%|█████▏    | 283/540 [33:31:51<40:01:02, 560.55s/it]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(model_results).sort_values(\"Coherence\", ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lda_model = LdaMulticore(corpus=corpus,\r\n",
    "                        id2word=id2word,\r\n",
    "                        num_topics=9, \r\n",
    "                        random_state=42,\r\n",
    "                        chunksize=chunksize,\r\n",
    "                        passes=passes,\r\n",
    "                        iterations=iterations,\r\n",
    "                        alpha=0.61,\r\n",
    "                        eta=0.31,\r\n",
    "                        eval_every=eval_every)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=docs, dictionary=dct, coherence='c_v')\r\n",
    "coherence_lda = coherence_model_lda.get_coherence()\r\n",
    "print('Coherence Score: ', coherence_lda)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize the topics\r\n",
    "pyLDAvis.enable_notebook()\r\n",
    "lda_vis = gensimvis.prepare(lda_model, corpus, dct)\r\n",
    "lda_vis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Supervised learning for text classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X =\r\n",
    "y = \r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
    "                                                    test_size=.75, \r\n",
    "                                                    stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) Support Vector Machine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = SVC(random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "params = {\"kernel\" : [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\r\n",
    "          \"decision_function_shape\" : [\"ovr\", \"ovo\"]}\r\n",
    "\r\n",
    "grid_search = GridSearchCV(svm_clf, \r\n",
    "                           param_grid=params, \r\n",
    "                           scoring=\"accuracy\",\r\n",
    "                           cv=5,\r\n",
    "                           n_jobs=-1)\r\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) Naive Bayes Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "nb_clf = MultinomialNB(random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db691860837755bfd223dbb19bf59c90fd58faf4b85973e04a456a30cef6b76b"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}